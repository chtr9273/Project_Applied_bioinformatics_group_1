#!/bin/bash
#SBATCH -A uppmax2025-2-380
#SBATCH -M pelle
#SBATCH -p pelle
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=16
#SBATCH --exclusive
#SBATCH -t 24:00:00
#SBATCH -J krakenuniq_taxonomic_profiling_data
#SBATCH -o /proj/uppmax2025-2-380/project_work/logs/02_krakenuniq_logs/%j.out
#SBATCH -e /proj/uppmax2025-2-380/project_work/logs/02_krakenuniq_logs/%j.err

# OBS: Remember to run as "sbatch --array=1-N%M krakenuniq_script.job batch_name sample_list"

set -euo pipefail

# Check command-line arguments
if [ $# -ne 2 ]; then
    echo "Usage: sbatch --array=1-N%M $0 <batch_name> <sample_list>"
    exit 1
fi

batch=$1
sample_list=$2

# Get sample name based on array index
sample=$(sed -n "${SLURM_ARRAY_TASK_ID}p" "$sample_list")

echo "Running script for sample $sample in $batch (Array index: $SLURM_ARRAY_TASK_ID)."

base=/proj/uppmax2025-2-380/project_work

# Load KrakenUniq
echo "Loading KrakenUniq in conda environment..."
module load Miniconda3/24.7.1-0
source activate "${base}/environments/conda_envs/krakenuniq"
echo "KrakenUniq loaded."


# Check that input FASTQ exists
input_fastq="${base}/data/01_host_removal/${batch}/host_removed/${sample}_unaligned_to_hg38.fastq.gz"
if [ ! -f "$input_fastq" ]; then
    echo "ERROR: Input FASTQ not found: $input_fastq"
    exit 1
fi

# Path to source DB
db_src=/proj/uppmax2025-2-380/private/DATA/DBDIR_KrakenUniq_MicrobialNT_Plus_CompleteGenomes
db_local="$SNIC_TMP/krakenuniq_db"

echo "Copying KrakenUniq database to job-local scratch..."
echo "Time: $(date)"
rm -rf "$db_local"  # ensure clean copy
rsync -a --whole-file --no-compress \
      --info=progress2 --stats --human-readable \
      "$db_src/" "$db_local/"
sync
echo "Database copy completed. Time: $(date)"

# Make sample-specific local scratch directory for output files
scratch_out=$SNIC_TMP/krakenuniq_output_${sample}
mkdir -p "$scratch_out"

# Local output files
classified="$scratch_out/${sample}.classified_sequences.krakenuniq"
unclassified="$scratch_out/${sample}.unclassified_sequences.krakenuniq"
output="$scratch_out/${sample}.sequences.krakenuniq"
report="$scratch_out/${sample}.krakenuniq.output"

echo "Performing KrakenUniq classification for sample: ${sample} at time: $(date) on node: $(hostname)."

krakenuniq --db "$db_local" \
    --fastq-input "$input_fastq" \
    --threads 16 --classified-out "$classified" \
    --unclassified-out "$unclassified" \
    --output "$output" \
    --report-file "$report"

echo "Done with KrakenUniq classification for sample: ${sample} at time: $(date)."
echo "Compressing outputs and moving files to output directory..."

# Gunzip large files, keep report file for later filtering
gzip -f "$classified" "$unclassified" "$output"

echo "Moving outputs to project directory..."
mkdir -p "${base}/data/02_krakenuniq/${batch}"
mv "$scratch_out"/* "${base}/data/02_krakenuniq/${batch}/"

echo "All done with sample: ${sample} at time: $(date)."